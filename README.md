# ğŸŒ¦ï¸ Weather Transformer from Scratch

> A physics-aware Vision Transformer for weather forecasting, built entirely from scratch in PyTorch.

**Built as preparation for GSoC 2026 â€” AI for Science**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ¯ Project Overview

This project implements a **Vision Transformer (ViT)** architecture for weather forecasting, trained on ERA5 reanalysis data. Key features:

- âœ… **Every component built from scratch** â€” no `nn.MultiheadAttention`
- âœ… **Physics-informed loss** â€” MSE + spatial smoothness + conservation constraints
- âœ… **Real climate data** â€” WeatherBench2 / ERA5 at 5.625Â° resolution
- âœ… **Comprehensive evaluation** â€” RMSE, MAE, ACC vs persistence baseline
- âœ… **Production-ready** â€” Config-driven training, checkpointing, logging

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Weather Transformer                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚   Input (B, 4, 32, 64)     4 weather variables, latÃ—lon     â”‚
â”‚          â”‚                                                   â”‚
â”‚          â–¼                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚   â”‚  Patch Embedding â”‚  Conv2d â†’ (B, 128, 256)              â”‚
â”‚   â”‚  (4Ã—4 patches)   â”‚  128 patches, 256-dim embeddings     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚            â”‚                                                 â”‚
â”‚            â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚   â”‚  + Positional    â”‚  Learnable spatial position info     â”‚
â”‚   â”‚    Encoding      â”‚                                       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚            â”‚                                                 â”‚
â”‚            â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚   â”‚  Transformer     â”‚  Ã— 6 layers                          â”‚
â”‚   â”‚  Encoder Blocks  â”‚  - Multi-Head Self-Attention (8h)    â”‚
â”‚   â”‚                  â”‚  - Feed-Forward MLP (4Ã— expansion)   â”‚
â”‚   â”‚                  â”‚  - Pre-Norm + Residual connections   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚            â”‚                                                 â”‚
â”‚            â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚   â”‚  Prediction Head â”‚  Linear â†’ Reshape â†’ (B, 4, 32, 64)   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                              â”‚
â”‚   Output: Predicted weather state at t+6h                    â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Results

### Model vs Persistence Baseline

| Metric | Model | Persistence | Improvement |
|--------|-------|-------------|-------------|
| **RMSE** | 0.3421 | 0.4156 | +17.7% âœ… |
| **MAE** | 0.2634 | 0.3201 | +17.7% âœ… |
| **ACC** | 0.892 | 0.834 | +7.0% âœ… |

> *Results on held-out test set. Persistence baseline: predict Y(t+1) = X(t).*

### Sample Prediction

![Prediction Sample](results/figures/prediction_sample.png)

*6-hour forecast for temperature at 850 hPa. Left: Input, Middle: Prediction, Right: Ground Truth*

---

## ğŸ“ Project Structure

```
weather-transformer-scratch/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml          # Hyperparameters & paths
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ download.py       # WeatherBench2 data download
â”‚   â”‚   â”œâ”€â”€ preprocess.py     # Preprocessing & normalization
â”‚   â”‚   â””â”€â”€ dataset.py        # PyTorch Dataset & DataLoader
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ patch_embedding.py
â”‚   â”‚   â”œâ”€â”€ positional_encoding.py
â”‚   â”‚   â”œâ”€â”€ attention.py      # Multi-head self-attention
â”‚   â”‚   â”œâ”€â”€ transformer_block.py
â”‚   â”‚   â”œâ”€â”€ weather_transformer.py
â”‚   â”‚   â””â”€â”€ physics_loss.py   # Physics-informed loss
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ trainer.py        # Training loop
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics.py        # RMSE, MAE, ACC
â”‚   â”‚   â””â”€â”€ evaluate.py       # Evaluation script
â”‚   â””â”€â”€ visualization/
â”‚       â”œâ”€â”€ plot_predictions.py
â”‚       â”œâ”€â”€ plot_loss.py
â”‚       â””â”€â”€ plot_attention.py
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_walkthrough.ipynb
â”‚   â””â”€â”€ 03_results_analysis.ipynb
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train.py              # Training entry point
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data.py          # Dataset tests (10)
â”‚   â”œâ”€â”€ test_model.py         # Model tests (51)
â”‚   â””â”€â”€ test_metrics.py       # Metrics tests (13)
â”œâ”€â”€ checkpoints/              # Saved model weights
â”œâ”€â”€ results/                  # Evaluation outputs
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone https://github.com/AswaniSahoo/weather-transformer-scratch.git
cd weather-transformer-scratch

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 2. Download Data

```bash
python src/data/download.py
python src/data/preprocess.py
```

### 3. Train Model

```bash
python scripts/train.py --config configs/default.yaml

# With overrides
python scripts/train.py --config configs/default.yaml --epochs 50 --device cuda
```

### 4. Evaluate

```bash
python -m src.evaluation.evaluate --checkpoint checkpoints/best_model.pt
```

### 5. Run Tests

```bash
pytest tests/ -v
```

---

## ğŸ”§ Configuration

All hyperparameters are defined in `configs/default.yaml`:

```yaml
model:
  in_channels: 4
  embed_dim: 256
  num_heads: 8
  num_layers: 6
  patch_size: 4
  mlp_ratio: 4.0
  dropout: 0.1

training:
  epochs: 50
  batch_size: 32
  learning_rate: 1.0e-4
  weight_decay: 0.01
  loss:
    mse_weight: 1.0
    smoothness_weight: 0.1
    conservation_weight: 0.05

data:
  variables: [t850, z500, u10, v10]
  lat_size: 32
  lon_size: 64
```

---

## ğŸ“ˆ Weather Variables

| Variable | Description | Level | Unit |
|----------|-------------|-------|------|
| `t850` | Temperature | 850 hPa | K |
| `z500` | Geopotential | 500 hPa | mÂ²/sÂ² |
| `u10` | U-wind component | 10m | m/s |
| `v10` | V-wind component | 10m | m/s |

---

## ğŸ§ª Testing

The project includes 74 comprehensive unit tests:

```bash
# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_model.py -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html
```

---

## ğŸ“š Key Components

### Physics-Informed Loss

```python
L = Î± Ã— MSE + Î² Ã— Smoothness + Î³ Ã— Conservation

# MSE: Standard pixel-wise reconstruction
# Smoothness: Penalizes unrealistic spatial gradients
# Conservation: Predicted global mean â‰ˆ target global mean
```

### Multi-Head Self-Attention (from scratch)

```python
# No nn.MultiheadAttention!
Q = x @ W_q  # Query projection
K = x @ W_k  # Key projection
V = x @ W_v  # Value projection

attention = softmax(Q @ K.T / sqrt(d_k)) @ V
```

---

## ğŸ“– References

1. **GraphCast** â€” Lam et al., DeepMind (2023) â€” [arXiv:2212.12794](https://arxiv.org/abs/2212.12794)
2. **FourCastNet** â€” Pathak et al., NVIDIA (2022) â€” [arXiv:2202.11214](https://arxiv.org/abs/2202.11214)
3. **ClimaX** â€” Nguyen et al., Microsoft (2023) â€” [arXiv:2301.10343](https://arxiv.org/abs/2301.10343)
4. **WeatherBench2** â€” Rasp et al. (2023) â€” [arXiv:2308.15560](https://arxiv.org/abs/2308.15560)
5. **Attention Is All You Need** â€” Vaswani et al. (2017) â€” [arXiv:1706.03762](https://arxiv.org/abs/1706.03762)
6. **Vision Transformer (ViT)** â€” Dosovitskiy et al. (2020) â€” [arXiv:2010.11929](https://arxiv.org/abs/2010.11929)

---

## ğŸ‘¤ Author

**Aswani Sahoo**

- GitHub: [@AswaniSahoo](https://github.com/AswaniSahoo)
- LinkedIn: [Aswani Sahoo](https://linkedin.com/in/aswanisahoo)

---

## ğŸ“ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

---

<p align="center">
  <i>Built with â¤ï¸ as preparation for GSoC 2026 â€” AI for Science</i>
</p>
